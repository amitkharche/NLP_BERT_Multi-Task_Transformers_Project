# ğŸ¤– BERT NLP Suite â€“ Multi-Task Transformers Pipeline

![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![HuggingFace](https://img.shields.io/badge/HuggingFace-ğŸ¤—-yellow.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)

---

## ğŸ“Œ Project Overview

This project provides a **multi-task NLP pipeline** powered by **BERT** and the Hugging Face ğŸ¤— Transformers library. It enables:

- âœ… **Sentiment Analysis**
- âœ… **Named Entity Recognition (NER)** 
- âœ… **Question Answering (QA)** 

It features:
- Custom training scripts
- Pre-trained model fine-tuning
- Streamlit-based interactive demo app
- Manual batching logic that avoids internal Keras errors (e.g., `unpack_x_y_sample_weight`)

---

## ğŸ¯ Business Use Case

In real-world applications, NLP can help:

- ğŸ“Š Understand user **sentiment** from reviews, feedback, or social media
- ğŸ·ï¸ Extract **key information** like names, places, and organizations from unstructured text
- â“ Enable **conversational Q&A** over structured documents or FAQs

### ğŸ’¡ Benefits
| Use Case              | Benefit                             |
|----------------------|-------------------------------------|
| Sentiment Analysis   | Brand monitoring, feedback mining   |
| Named Entity Recognition | Information extraction, resume parsing |
| Question Answering   | Instant support, document querying  |

---

## ğŸ—‚ï¸ Project Structure

```plaintext
transformers-bert-nlp/
â”œâ”€â”€ data/                            # Dataset placeholder
â”œâ”€â”€ notebooks/                       # EDA & model experimentation notebooks
â”‚   â”œâ”€â”€ 01_BERT_QA.ipynb
â”‚   â”œâ”€â”€ 02_BERT_Sentiment.ipynb
â”‚   â””â”€â”€ 03_BERT_NER.ipynb
â”œâ”€â”€ output/                          # Saved fine-tuned models
â”‚   â”œâ”€â”€ bert_sentiment_custom/
â”‚   â””â”€â”€ bert_ner/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py                     # Training script for sentiment and NER
â”‚   â””â”€â”€ evaluate.py                  # Model evaluation script (optional)
â”œâ”€â”€ streamlit_app/
â”‚   â””â”€â”€ app.py                       # Streamlit interface
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ LICENSE                          # MIT License
â””â”€â”€ README.md                        # You are here
```

---

## âš™ï¸ Installation & Setup

### ğŸ”§ Clone and Install

```bash
git clone https://github.com/amitkharche/NLP_BERT_Multi-Task_Transformers_Project.git
cd NLP_BERT_Multi-Task_Transformers_Project
pip install -r requirements.txt
```

### ğŸ“¦ Requirements

- Python â‰¥ 3.8
- TensorFlow â‰¥ 2.8
- transformers â‰¥ 4.30
- datasets
- streamlit
- plotly
- pandas

---

## ğŸš€ How to Use

### ğŸ¯ Model Training (Sentiment or NER)

Run from root folder:

```bash
python src/train.py --task sentiment
python src/train.py --task ner
```

> ğŸ’¡ Automatically downloads the dataset (IMDB or CoNLL-2003), fine-tunes BERT, and saves the model under `/output`.

### ğŸŒ Launch Streamlit UI

```bash
streamlit run streamlit_app/app.py
```

Then open your browser at: [http://localhost:8501](http://localhost:8501)

---

## ğŸ§  Tasks Covered

### ğŸŸ¢ Sentiment Analysis

- Dataset: IMDB Movie Reviews
- Model: `TFBertForSequenceClassification`
- Labels: POSITIVE / NEGATIVE
- Output: `output/bert_sentiment_custom/`

### ğŸŸ  Named Entity Recognition (NER)

- Dataset: CoNLL-2003
- Model: `TFBertForTokenClassification`
- Entities: `PER`, `ORG`, `LOC`, `MISC`
- Output: `output/bert_ner/`

### ğŸ”µ Question Answering

- Model: `pipeline("question-answering")` using `bert-base-uncased`
- Context + Question input in Streamlit
- No training script; uses pre-trained inference only

---

## ğŸ§ª Sample Inputs

### ğŸ“ Sentiment Analysis

> Text: "I absolutely loved the new Batman movie. It was thrilling!"

**â†’ Output**: `POSITIVE (Confidence: 97%)`

---

### ğŸ· Named Entity Recognition

> Text: "Elon Musk is the CEO of Tesla, based in Palo Alto, California."

**â†’ Output**:
| Entity     | Type | Confidence |
|------------|------|------------|
| Elon Musk  | PER  | 98.4%      |
| Tesla      | ORG  | 95.2%      |
| Palo Alto  | LOC  | 93.6%      |
| California | LOC  | 92.1%      |

---

### â“ Question Answering

> **Context**: "The Eiffel Tower is in Paris, France. It was built in 1889."

> **Question**: "When was the Eiffel Tower built?"

**â†’ Output**: `"1889"` with 98.2% confidence

---

## ğŸ“Š Model Evaluation (Optional)

You can add or run evaluation metrics (accuracy, F1, etc.) by extending `src/evaluate.py` (template stub provided).

---

## ğŸ›  Tools & Libraries

- ğŸ¤— **Transformers** â€“ Model architectures
- ğŸ§  **TensorFlow** â€“ Training framework
- ğŸ“š **datasets** â€“ Prebuilt NLP datasets
- ğŸ› **Streamlit** â€“ Interactive user interface
- ğŸ“ˆ **Plotly** â€“ Visualizations
- ğŸ **Python 3.8+**

---

## ğŸ“ License

This project is licensed under the **MIT License** â€“ free to use, modify, and distribute.

---

## ğŸ¤ Let's Connect

Have questions, suggestions, or ideas to collaborate?

- ğŸŒ [LinkedIn](https://www.linkedin.com/in/amit-kharche)
- ğŸ§  [Medium](https://medium.com/@amitkharche14)
- ğŸ’» [GitHub](https://github.com/amitkharche)

---

## ğŸ’¬ Final Words

Whether you're a developer building customer-facing tools, a researcher exploring NLP models, or a student learning transformers â€” this project offers a ready-to-use suite for training, inference, and deployment. Clone it, customize it, and bring your NLP ideas to life.
